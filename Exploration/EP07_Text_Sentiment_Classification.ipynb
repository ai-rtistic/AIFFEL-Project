{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "inside-relief",
   "metadata": {},
   "source": [
    "# Exploration 7. IMDb 영화리뷰 감성분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-trout",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/84179578/128654348-631dc893-cc14-4321-9543-43aefff28c05.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-lafayette",
   "metadata": {},
   "source": [
    "IMDb Large Movie Dataset은 50000개의 영어로 작성된 영화 리뷰 텍스트로 구성되어 있으며, 긍정은 1, 부정은 0의 라벨로 구성되어 있다.  \n",
    "\n",
    "IMDb 영화리뷰 감성분석을 실제로 진행해보자.\n",
    "\n",
    "_이후 스텝의 IMDb 데이터셋 처리 코드 중 일부는 Tensorflow 튜토리얼에 언급된 데이터 전처리 로직을 참고하였음_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-large",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dental-reader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-edinburgh",
   "metadata": {},
   "source": [
    "`imdb.load_data()` 호출 시 단어사전에 등재할 단어의 개수(num_words)를 10000으로 지정하면, 그 개수만큼의 `word_to_index` 딕셔너리까지 생성된 형태로 데이터셋이 생성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dated-longitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-reporter",
   "metadata": {},
   "source": [
    "텍스트 데이터가 아니라 이미 숫자로 encode된 텍스트 데이터를 다운로드받았음을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "massive-venezuela",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력\n",
    "print(word_to_index['the'])  # 1 이 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-disney",
   "metadata": {},
   "source": [
    "IMDb 데이터셋의 텍스트 인코딩을 위한 word_to_index, index_to_word는 아래와 같이 보정되어야 한다.  \n",
    "\n",
    "`word_to_index` 는 IMDb 텍스트 데이터셋의 단어 출현 빈도 기준으로 내림차수 정렬되어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "latin-lounge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "affecting-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-courtesy",
   "metadata": {},
   "source": [
    "encode된 텍스트가 정상적으로 decode되는지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "empty-allowance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-sally",
   "metadata": {},
   "source": [
    "`pad_sequences` 를 통해 데이터셋 상의 문장의 길이를 통일해야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-samba",
   "metadata": {},
   "source": [
    "문장 최대 길이 maxlen의 값 설정도 전체 모델 성능에 영향을 미치게 된다. 이 길이도 적절한 값을 찾기 위해서는 전체 데이터셋의 분포를 확인해 보는 것이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "favorite-murder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-rocket",
   "metadata": {},
   "source": [
    "### padding 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-processor",
   "metadata": {},
   "source": [
    "padding 방식을 문장 뒤쪽('post')과 앞쪽('pre') 중 어느쪽으로 하느냐에 따라 RNN을 이용한 딥러닝 적용 시 성능 차이가 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-exercise",
   "metadata": {},
   "source": [
    "RNN은 입력데이터가 순차적으로 처리되어, 가장 마지막 입력이 최종 state 값에 가장 영향을 많이 미치게 된다. 그러므로 마지막 입력이 무의미한 padding으로 채워지는 것은 비효율적이다.  \n",
    "\n",
    "따라서 'pre'가 훨씬 유리하며, 10% 이상의 테스트 성능 차이를 보이게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "measured-iceland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre',\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', \n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-fitting",
   "metadata": {},
   "source": [
    "## 2. RNN 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hazardous-replication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = 10000 # 어휘 사전의 크기 (10,000개의 단어)\n",
    "word_vector_dim = 16 # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 설계.\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-suicide",
   "metadata": {},
   "source": [
    "### validation set 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "broad-slovakia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-geology",
   "metadata": {},
   "source": [
    "## 3. 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "electrical-crazy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 7s 138ms/step - loss: 0.6922 - accuracy: 0.5308 - val_loss: 0.6870 - val_accuracy: 0.5880\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 3s 112ms/step - loss: 0.6797 - accuracy: 0.6192 - val_loss: 0.6558 - val_accuracy: 0.6599\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 3s 112ms/step - loss: 0.6091 - accuracy: 0.7245 - val_loss: 0.4982 - val_accuracy: 0.8270\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 3s 112ms/step - loss: 0.5272 - accuracy: 0.7985 - val_loss: 0.4828 - val_accuracy: 0.8201\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 3s 108ms/step - loss: 0.4213 - accuracy: 0.8664 - val_loss: 0.4237 - val_accuracy: 0.8416\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 3s 107ms/step - loss: 0.3354 - accuracy: 0.9007 - val_loss: 0.4032 - val_accuracy: 0.8471\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 3s 107ms/step - loss: 0.2880 - accuracy: 0.9145 - val_loss: 0.3765 - val_accuracy: 0.8503\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.2379 - accuracy: 0.9303 - val_loss: 0.3703 - val_accuracy: 0.8515\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.1988 - accuracy: 0.9466 - val_loss: 0.3699 - val_accuracy: 0.8508\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 0.1674 - accuracy: 0.9557 - val_loss: 0.4033 - val_accuracy: 0.8472\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.1506 - accuracy: 0.9596 - val_loss: 0.3922 - val_accuracy: 0.8501\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 3s 105ms/step - loss: 0.1287 - accuracy: 0.9675 - val_loss: 0.4109 - val_accuracy: 0.8483\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.1197 - accuracy: 0.9690 - val_loss: 0.4216 - val_accuracy: 0.8465\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.1065 - accuracy: 0.9747 - val_loss: 0.4312 - val_accuracy: 0.8476\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.0951 - accuracy: 0.9775 - val_loss: 0.4470 - val_accuracy: 0.8472\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.0899 - accuracy: 0.9781 - val_loss: 0.4664 - val_accuracy: 0.8486\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.0843 - accuracy: 0.9801 - val_loss: 0.4889 - val_accuracy: 0.8448\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.0720 - accuracy: 0.9846 - val_loss: 0.4952 - val_accuracy: 0.8427\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.0742 - accuracy: 0.9844 - val_loss: 0.5030 - val_accuracy: 0.8425\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.0721 - accuracy: 0.9845 - val_loss: 0.5243 - val_accuracy: 0.8411\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-seller",
   "metadata": {},
   "source": [
    "학습이 끝난 모델을 test set 으로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "interpreted-palestinian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 21s - loss: 0.5518 - accuracy: 0.8345\n",
      "[0.5518251657485962, 0.8345199823379517]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-parliament",
   "metadata": {},
   "source": [
    "### 학습과정 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "speaking-double",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adverse-metallic",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "addressed-surge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-glass",
   "metadata": {},
   "source": [
    "Training and validation loss를 그려 보면, 몇 epoch까지의 트레이닝이 적절한지 최적점을 추정할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-tuner",
   "metadata": {},
   "source": [
    "## Word2Vec 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-creek",
   "metadata": {},
   "source": [
    "이전 스텝에서 라벨링 비용이 많이 드는 머신러닝 기반 감성분석의 비용을 절감하면서 정확도를 크게 향상시킬 수 있는 자연어처리 기법으로 단어의 특성을 저차원 벡터값으로 표현할 수 있는 워드 임베딩(word embedding) 기법으 사용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-airfare",
   "metadata": {},
   "source": [
    "사용했던 model의 첫 번째 레이어는 바로 Embedding 레이어였다. 이 레이어는 우리가 가진 사전의 단어 개수 X 워드 벡터 사이즈만큼의 크기를 가진 학습 파라미터였다.  \n",
    "\n",
    "만약 우리의 감성분류 모델이 학습이 잘 되었다면, Embedding 레이어에 학습된 우리의 워드 벡터들도 의미 공간상에 유의미한 형태로 학습되었을 것. \n",
    "\n",
    "한번 확인해보자.\n",
    "\n",
    "워드벡터를 다루는데 유용한 `gensim` 패키지를 설치한다.\n",
    "```\n",
    "$ pip install gensim\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beautiful-lafayette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "mathematical-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-calibration",
   "metadata": {},
   "source": [
    "`gensim`에서 제공하는 패키지를 이용해, 위에 남긴 임베딩 파라미터를 읽어서 word vector로 활용 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "progressive-ozone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03434632,  0.05501131,  0.01996197, -0.00385678,  0.07030047,\n",
       "       -0.04595968, -0.02682209, -0.02869963, -0.00058966,  0.0657869 ,\n",
       "       -0.0168556 ,  0.00032998, -0.01604367,  0.0455179 ,  0.00747465,\n",
       "        0.03030313], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-wright",
   "metadata": {},
   "source": [
    "워드 벡터가 의미벡터 공간상에 유의미하게 학습되었는지 확인하는 방법 중에, 단어를 하나 주고 그와 가장 유사한 단어와 그 유사도를 확인하는 방법이 있다. `gensim` 을 사용해 아래와 같이 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "closing-resident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('round', 0.97539222240448),\n",
       " ('stanwyck', 0.9742845296859741),\n",
       " ('reverse', 0.9733150005340576),\n",
       " ('learns', 0.9721903800964355),\n",
       " ('gas', 0.9701603055000305),\n",
       " ('vincenzo', 0.9691139459609985),\n",
       " ('readily', 0.9678806662559509),\n",
       " ('email', 0.9670338034629822),\n",
       " ('seat', 0.9666711688041687),\n",
       " ('larger', 0.9658933877944946)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-adobe",
   "metadata": {},
   "source": [
    "love라는 단어와 유사한 다른 단어를 그리 잘 찾았다고 느껴지지는 않는다.  \n",
    "\n",
    "감성분류 태스크를 잠깐 학습한 것만으로 워드 벡터가 유의미하게 학습되기는 어려운 것 같다. 우리가 다룬 정도의 훈련데이터로는 워드 벡터를 정교하게 학습시키기 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-powell",
   "metadata": {},
   "source": [
    "그래서 이번에는 구글에서 제공하는 Word2Vec이라는 사전학습된(Pretrained) 워드 임베딩 모델을 가져다 활용해 보겠다.   \n",
    "Word2Vec은 무려 1억 개의 단어로 구성된 Google News dataset을 바탕으로 학습되었다. 총 300만 개의 단어를 각각 300차원의 벡터로 표현한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "retired-jackson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-rendering",
   "metadata": {},
   "source": [
    "300dim의 벡터로 이루어진 300만 개의 단어이다.  \n",
    "`KeyedVectors.load_word2vec_format` 메소드로 워드 벡터를 로딩할 때 가장 많이 사용되는 상위 100만 개만 limt으로 조건을 주어 로딩하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "starting-husband",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-tours",
   "metadata": {},
   "source": [
    "Word2Vec에서 제공하는 워드 임베딩 벡터들끼리는 의미적 유사도가 가까운 것이 서로 가깝게 제대로 학습된 것을 확인할 수 있다.  \n",
    "이제 이전 스텝에서 학습했던 모델의 임베딩 레이어를 Word2Vec의 것으로 교체하여 다시 학습시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "played-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "imported-nursery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "broad-switch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 16s 447ms/step - loss: 0.6996 - accuracy: 0.5200 - val_loss: 0.6706 - val_accuracy: 0.6058\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 11s 376ms/step - loss: 0.6456 - accuracy: 0.6421 - val_loss: 0.5838 - val_accuracy: 0.7104\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 11s 385ms/step - loss: 0.5040 - accuracy: 0.7809 - val_loss: 0.5233 - val_accuracy: 0.7286\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 11s 370ms/step - loss: 0.3628 - accuracy: 0.8412 - val_loss: 0.3492 - val_accuracy: 0.8474\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 11s 372ms/step - loss: 0.2481 - accuracy: 0.9067 - val_loss: 0.3264 - val_accuracy: 0.8615\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 11s 374ms/step - loss: 0.1720 - accuracy: 0.9453 - val_loss: 0.3256 - val_accuracy: 0.8652\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 11s 366ms/step - loss: 0.1237 - accuracy: 0.9688 - val_loss: 0.3417 - val_accuracy: 0.8596\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 12s 394ms/step - loss: 0.0870 - accuracy: 0.9815 - val_loss: 0.3438 - val_accuracy: 0.8659\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 12s 387ms/step - loss: 0.0623 - accuracy: 0.9900 - val_loss: 0.3831 - val_accuracy: 0.8545\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 11s 366ms/step - loss: 0.0444 - accuracy: 0.9952 - val_loss: 0.3788 - val_accuracy: 0.8628\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 11s 369ms/step - loss: 0.0305 - accuracy: 0.9980 - val_loss: 0.3983 - val_accuracy: 0.8634\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 11s 366ms/step - loss: 0.0209 - accuracy: 0.9990 - val_loss: 0.4114 - val_accuracy: 0.8641\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 11s 377ms/step - loss: 0.0148 - accuracy: 0.9992 - val_loss: 0.4275 - val_accuracy: 0.8623\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 11s 367ms/step - loss: 0.0118 - accuracy: 0.9993 - val_loss: 0.4430 - val_accuracy: 0.8630\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 11s 382ms/step - loss: 0.0087 - accuracy: 0.9996 - val_loss: 0.4600 - val_accuracy: 0.8645\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 11s 375ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.4730 - val_accuracy: 0.8628\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 11s 368ms/step - loss: 0.0050 - accuracy: 0.9997 - val_loss: 0.4936 - val_accuracy: 0.8628\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 11s 376ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 0.5145 - val_accuracy: 0.8635\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 11s 371ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5354 - val_accuracy: 0.8625\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 12s 384ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.5558 - val_accuracy: 0.8625\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "stock-husband",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 8s - loss: 0.6044 - accuracy: 0.8493\n",
      "[0.6044328808784485, 0.8492799997329712]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-montgomery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
