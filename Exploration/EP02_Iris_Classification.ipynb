{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "informal-distributor",
   "metadata": {},
   "source": [
    "# <font color=red> Exploration 2. Iris(붓꽃) 분류</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-connectivity",
   "metadata": {},
   "source": [
    "프랑스의 국화인 __Iris(붓꽃)__ 데이터를 분류해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-phone",
   "metadata": {},
   "source": [
    "Scikit-learn 에서는 예제로 활용해 볼 수 있는 7가지의 Toy datasets 와 7가지의 Real world datasets 를  제공한다.  \n",
    "\n",
    "Toy datasats 중 한가지가 이번에 다뤄볼 __Iris dataset__ 이다.  \n",
    "\n",
    "iris dataset 의 sepal(꽃받침)과 petal(꽃잎)의 길이와 폭을 가지고 세 개의 품종(setosa, versicolor, virginica) 으로 분류하는 모델을 만들어보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-group",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/84179578/125756842-ae86e9e6-1ae4-42c5-a3cf-90bda928748c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-natural",
   "metadata": {},
   "source": [
    "## 데이터 정보 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-respect",
   "metadata": {},
   "source": [
    "데이터셋을 다루기 전에 먼저 데이터셋의 정보를 확인해야한다.  \n",
    "데이터에 대한 이해도는  해당 데이터를 활용한 결과와 성능에 큰 영향을 미치기때문!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-register",
   "metadata": {},
   "source": [
    "[Scikit-learn Iris plants dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-plants-dataset) 에서 iris 데이터셋에 대한 정보를 확인해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-plaza",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/84179578/125756953-1a934b1a-3db5-4589-a51d-27ba791cc13a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-press",
   "metadata": {},
   "source": [
    "위와 같이, 데이터에 대한 다양한 기본 정보들을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-selling",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comparative-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'filename', 'frame', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "print(dir(iris))  # dir : 객체가 어떤 변수와 메소드를 가지고 있는지 나열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reflected-bidding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()  # iris 에 담긴 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fiscal-mapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "[5.1 3.5 1.4 0.2]\n"
     ]
    }
   ],
   "source": [
    "iris_data = iris.data   # iris 의 데이터를 변수에 저장\n",
    "\n",
    "print(iris_data.shape)\n",
    "print(iris_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-hunter",
   "metadata": {},
   "source": [
    "iris의 데이터는 총 150개의 데이터가 각각 4개의 정보를 담고 있는 것을 확인 할 수 있다.  \n",
    "\n",
    "0번 index의 데이터를 보니, 순서대로 sepal length, sepal width, petal length, petal width 의 값이 담겨있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-university",
   "metadata": {},
   "source": [
    "그럼 이제 위 4개의 정보를 입력했을때 붓꽃의 품종을 출력하도록 해야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-lincoln",
   "metadata": {},
   "source": [
    "머신러닝 모델이 출력해야 하는 정답을 __라벨(label)__ 또는 __타겟(target)__ 이라고 한다.  \n",
    "iris 데이터에서 `target`에 해당 타겟 정보가 담겨있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "integral-merchant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_label = iris.target   # 타겟정보를 변수에 저장\n",
    "print(iris_label.shape)\n",
    "iris_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-stuff",
   "metadata": {},
   "source": [
    "이외의 메소드들의 역할은 다음과 같다.\n",
    "- `target_names` : 라벨 이름\n",
    "- `DESCR` : 데이터셋에 대한 설명\n",
    "- `feature_names` : 각 feature 이름\n",
    "- `filename` : 데이터셋 파일이 저장된 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "optical-contact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names   # 라벨 이름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-poland",
   "metadata": {},
   "source": [
    "순서 그대로 target 값이 \n",
    "`0` 이면 `setosa`,\n",
    "`1` 이면 `versicolor`,\n",
    "`2` 이면 `virginica` 를 나타낸다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "employed-india",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)    # 데이터셋에 대한 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-chance",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-baking",
   "metadata": {},
   "source": [
    "## 데이터 다루기 (training set, test set 나누기)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-valve",
   "metadata": {},
   "source": [
    "iris 데이터는 행과 열이 있는 2차원 데이터이므로 2차원 배열 데이터를 다루는데 가장 많이 쓰이는 도구인 `pandas` 를 활용하겠다.  \n",
    "\n",
    "먼저, iris 데이터를 DataFrame 자료형으로 변환하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "played-opposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-punch",
   "metadata": {},
   "source": [
    "타겟 데이터도  label 이라는 컬럼으로 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "comparable-equation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     label  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "145      2  \n",
       "146      2  \n",
       "147      2  \n",
       "148      2  \n",
       "149      2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df[\"label\"] = iris.target\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-juvenile",
   "metadata": {},
   "source": [
    "`sklearn,model_selection` 패키지의 `train_test_split` 함수를 활용하여, training set 와 test set 을 나눌수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "occasional-works",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  120 , X_test 개수:  30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "print('X_train 개수: ', len(X_train), ', X_test 개수: ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-monkey",
   "metadata": {},
   "source": [
    "`train_test_split` 함수의 파라미터를 정리하면\n",
    "- __첫번째 파라미터__ : feature (특징)\n",
    "- __두번째 파라미터__ : label (정답)\n",
    "- __test_size__ : training set 과 test set 의 비율.  \n",
    "위 코드에서는 전체 데이터의 20%를 test set 으로 사용하여, 8:2 비율로 training set 과 test set 으로 나눔\n",
    "- __random_state__ :  랜덤하게 섞는 과정에서 일정한 결과값을 보여주기 위해 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "waiting-health",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (120,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "secret-booth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 4), (30,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-humanity",
   "metadata": {},
   "source": [
    "## Decision Tree 모델 사용하여 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-journal",
   "metadata": {},
   "source": [
    "지금 하고자하는 iris 데이터에 대한 문제는 label(정답) 이 있으므로 __지도학습 (Supervised Learning)__ 에 해당한다.  \n",
    "또한 입력 데이터를 통해 특정 카테고리 중 하나로 분류해내는 __분류 (Classification)__ 에 해당한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-research",
   "metadata": {},
   "source": [
    "수많은 분류 모델 중 __Decision Tree 모델__ 을 사용해보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-spoke",
   "metadata": {},
   "source": [
    "Decision Tree (결정트리) 에 대한 내용은 블로그에 자세히 정리하였다.  \n",
    "> 블로그 링크 추가 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-compression",
   "metadata": {},
   "source": [
    "Decision Tree 는 `sklearn.tree` 패키지 안에 `DecisionTreeClassifier` 라는 이름으로 내장되어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "radio-chemistry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "print(decision_tree._estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "comparative-lloyd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-manufacturer",
   "metadata": {},
   "source": [
    "`fit` 함수를 통해 모델을 학습시켰다. 모델을 training set 으로 학습시킨다는 개념이 training set에 맞게 모델을 맞추는것(fit) 이라고 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "referenced-semester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 2, 0, 1, 1, 0, 1, 2, 1, 0, 2, 0, 2, 2, 2, 0, 0, 1, 2,\n",
       "       1, 1, 2, 2, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = decision_tree.predict(X_test)  # X_test 데이터로 예측한 값을 y_pred 에 저장\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "amino-georgia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 2, 2, 0, 0, 1, 2,\n",
       "       1, 2, 2, 2, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-mailing",
   "metadata": {},
   "source": [
    "`y_pred` 와 `y_test` 데이터를 눈으로 간단히 비교해보면 어느 정도 잘 맞은것을 확인할 수 있다.  \n",
    "\n",
    "`sklearn.metrics` 패키지를 이용하면 예측한 결과에 대한 수치를 편리하게 확인할 수 있다.  \n",
    "성능을 평가하는 방법에는 다양한 척도가 있는데, 그 중 __정확도 (Accuracy)__ 를 확인해보자.  \n",
    "\n",
    "정확도는 전체 개수 중 맞은 것의 개수의 수치이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dedicated-snapshot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred) # 실제 라벨값, 예측한 라벨값\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-capital",
   "metadata": {},
   "source": [
    "Iris 데이터를 이용해 Decision Tree 모델을 학습시키고 분류하는 전체 과정은 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hazardous-principal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.91      0.83      0.87        12\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.91      0.91      0.91        30\n",
      "weighted avg       0.90      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# (2) 데이터 준비\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target\n",
    "\n",
    "# (3) train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-approval",
   "metadata": {},
   "source": [
    "여기서 모델을 바꾸고 싶다면 `(4) 모델 학습 및 예측` 부분에서 사용할 모델로 바꾸면 된다.  \n",
    "\n",
    "다른 scikit-learn 내장 분류 모델에 대한 자세한 내용은 블로그에 정리하겠다.\n",
    "> 블로그 링크 추가 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-exemption",
   "metadata": {},
   "source": [
    "## RandomForest 모델 사용하여 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-playlist",
   "metadata": {},
   "source": [
    "간단히, Decision Tree를 여러개 모아놓은 __RandomForest__ 모델을 사용하겠다.  \n",
    "단일 모델을 여러개 사용함으로써 한 개만 사용할 때 생기는 문제를 극복하는 기법을 __앙상블(Ensemble) 기법__ 이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-ireland",
   "metadata": {},
   "source": [
    "`sklearn.ensemble` 패키지 내에 있는 `RandomForestClssifier` 을 사용해 RandomForest 모델을 사용해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "relative-communist",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      0.83      0.91        12\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.94      0.93        30\n",
      "weighted avg       0.95      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-suite",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) 모델 사용하여 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "funky-athletics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       0.91      0.83      0.87        12\n",
      "           2       0.75      0.86      0.80         7\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.89      0.90      0.89        30\n",
      "weighted avg       0.91      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-gasoline",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent Classifier (SGDClassifier) 모델 사용하여 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "still-george",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       0.86      1.00      0.92        12\n",
      "           2       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.95      0.90      0.92        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-shopper",
   "metadata": {},
   "source": [
    "## 모델 성능 평가의 다양한 척도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-league",
   "metadata": {},
   "source": [
    "이때까지 우리는 정확도로 모델의 성능을 평가하였다. 하지만 정확도는 확실한 단점이 있다. \n",
    "\n",
    "따라서 __오차행렬 (Confusion)__ 을 사용하여 다양한 척도로 모델의 성능을 평가한다.  \n",
    "오차 행렬은 `sklearn.metrics` 패키지 내의 `confusion_matrix`로 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-cabin",
   "metadata": {},
   "source": [
    "정확도의 단점과 오차행렬에 대한 자세한 내용은 블로그에 정리하였다.\n",
    "> 블로그 링크 추가 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-taste",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
