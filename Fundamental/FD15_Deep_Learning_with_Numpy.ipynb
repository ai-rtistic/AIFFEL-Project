{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dimensional-seattle",
   "metadata": {},
   "source": [
    "# Funadamental 15. Deep Learning with Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-installation",
   "metadata": {},
   "source": [
    "딥러닝 프레임워크를 이용하면 몇 줄 안되는 코드만으로 MNIST 데이터셋을 99% 이상의 정확도로 분류할 수 있는 이미지 분류기를 만들 수 있으며, 이를 활용해서 다양한 카테고리의 이미지 분류기로 확장할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-nomination",
   "metadata": {},
   "source": [
    "`Tensorflow`를 사용해 아래와 같이 MNIST 이미지 분류 모델을 구현 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demanding-native",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.8290 - accuracy: 0.8108\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2441 - accuracy: 0.9322\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1850 - accuracy: 0.9471\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1528 - accuracy: 0.9566\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1285 - accuracy: 0.9640\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1130 - accuracy: 0.9682\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1001 - accuracy: 0.9716\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0887 - accuracy: 0.9754\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0805 - accuracy: 0.9770\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0713 - accuracy: 0.9806\n",
      "313/313 - 0s - loss: 0.0996 - accuracy: 0.9698\n",
      "test_loss: 0.09957778453826904 \n",
      "test_accuracy: 0.9697999954223633\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST 데이터를 로드. 다운로드하지 않았다면 다운로드까지 자동으로 진행됩니다. \n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
    "\n",
    "# 모델에 맞게 데이터 가공\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "x_train_reshaped = x_train_norm.reshape(-1, x_train_norm.shape[1]*x_train_norm.shape[2])\n",
    "x_test_reshaped = x_test_norm.reshape(-1, x_test_norm.shape[1]*x_test_norm.shape[2])\n",
    "\n",
    "# 딥러닝 모델 구성 - 2 Layer Perceptron\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='sigmoid', input_shape=(784,)))  # 입력층 d=784, 은닉층 레이어 H=50\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))   # 출력층 레이어 K=10\n",
    "model.summary()\n",
    "\n",
    "# 모델 구성과 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)\n",
    "\n",
    "# 모델 테스트 결과\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-albania",
   "metadata": {},
   "source": [
    "인공신경망의 실제 구현 원리를 보다 명확하게 이해하기 위해, 그동안 들춰보지 않았던 프레임워크 내부에서 일어나는 일을 Numpy를 활용해 직접 구현해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-plenty",
   "metadata": {},
   "source": [
    "## Parameters, Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greenhouse-movie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(5, 784)\n"
     ]
    }
   ],
   "source": [
    "# 입력층 데이터의 모양(shape)\n",
    "print(x_train_reshaped.shape)\n",
    "\n",
    "# 테스트를 위해 x_train_reshaped의 앞 5개의 데이터를 가져온다.\n",
    "X = x_train_reshaped[:5]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "serious-clock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(5, 50)\n"
     ]
    }
   ],
   "source": [
    "weight_init_std = 0.1\n",
    "input_size = 784\n",
    "hidden_size=50\n",
    "\n",
    "# 인접 레이어간 관계를 나타내는 파라미터 W를 생성하고 random 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)  \n",
    "# 바이어스 파라미터 b를 생성하고 Zero로 초기화\n",
    "b1 = np.zeros(hidden_size)\n",
    "\n",
    "a1 = np.dot(X, W1) + b1   # 은닉층 출력\n",
    "\n",
    "print(W1.shape)\n",
    "print(b1.shape)\n",
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lesser-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 레이어 구현 함수\n",
    "def affine_layer_forward(X, W, b):\n",
    "    y = np.dot(X, W) + b\n",
    "    cache = (X, W, b)\n",
    "    return y, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-channel",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unique-object",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26390524 0.63106056 0.60116598 0.31773646 0.36543719 0.12229437\n",
      " 0.60021896 0.74428202 0.59876258 0.76574893 0.26534045 0.55134929\n",
      " 0.03749032 0.73699956 0.5926007  0.46339302 0.88153112 0.35851286\n",
      " 0.7225068  0.27788059 0.3754259  0.45128955 0.31703203 0.369361\n",
      " 0.4846993  0.26576593 0.73994846 0.7061886  0.80311133 0.34625307\n",
      " 0.7099918  0.67509669 0.40164588 0.55323731 0.44801892 0.62871617\n",
      " 0.56347226 0.45351599 0.64622419 0.52546016 0.37645857 0.34870831\n",
      " 0.35513843 0.66196719 0.33195126 0.78948553 0.09831935 0.32469885\n",
      " 0.77631985 0.31254014]\n"
     ]
    }
   ],
   "source": [
    "# 위 수식의 sigmoid 함수를 구현해 봅니다.\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "\n",
    "\n",
    "z1 = sigmoid(a1)\n",
    "print(z1[0])  # sigmoid의 출력은 모든 element가 0에서 1사이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-travel",
   "metadata": {},
   "source": [
    "sigmoid 다음에 다시 Dense 레이어가 출현한다. 출력 노드 개수만 다를 뿐 동일한 구조입니다. 그렇다면 MLP 레이어를 아래와 같이 함수로 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sharp-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 레이어 구현 함수\n",
    "def affine_layer_forward(X, W, b):\n",
    "    y = np.dot(X, W) + b\n",
    "    cache = (X, W, b)\n",
    "    return y, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "regional-salem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04744956  0.31375866  0.05320329 -0.04925392 -0.46085205 -0.25914571\n",
      " -0.48645869 -0.54343351  0.34504656  0.18312109]\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)    # z1이 다시 두번째 레이어의 입력이 됩니다. \n",
    "\n",
    "print(a2[0])  # 최종 출력이 output_size만큼의 벡터가 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-movement",
   "metadata": {},
   "source": [
    "최종 출력인 `a2`에 softmax 함수를 적용하면 모델의 출력은 입력 X가 10가지 숫자 중 하나일 확률의 형태로 가공된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "advance-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unlimited-discipline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10883441, 0.14204397, 0.10946242, 0.09880262, 0.06546568,\n",
       "       0.08009651, 0.0638106 , 0.06027663, 0.14655849, 0.12464867])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = softmax(a2)\n",
    "y_hat[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "median-company",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 라벨을 One-hot 인코딩하는 함수\n",
    "def _change_one_hot_label(X, num_category):\n",
    "    T = np.zeros((X.size, num_category))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "Y_digit = y_train[:5]\n",
    "t = _change_one_hot_label(Y_digit, 10)\n",
    "t     # 정답 라벨의 One-hot 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "historical-possession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10883441 0.14204397 0.10946242 0.09880262 0.06546568 0.08009651\n",
      " 0.0638106  0.06027663 0.14655849 0.12464867]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_hat[0])\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "authorized-buffer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02176688,  0.02840879,  0.02189248,  0.01976052,  0.01309314,\n",
       "        -0.1839807 ,  0.01276212,  0.01205533,  0.0293117 ,  0.02492973],\n",
       "       [-0.17975727,  0.03017864,  0.02021959,  0.01941245,  0.01126083,\n",
       "         0.01689275,  0.01393851,  0.01154803,  0.03422212,  0.02208435],\n",
       "       [ 0.0237011 ,  0.02948237,  0.02540966,  0.01641073, -0.18978735,\n",
       "         0.01561649,  0.01479889,  0.0109042 ,  0.0320069 ,  0.02145702],\n",
       "       [ 0.01908193, -0.16993201,  0.02120276,  0.01889285,  0.01338442,\n",
       "         0.02220483,  0.01405607,  0.01181776,  0.02741587,  0.02187552],\n",
       "       [ 0.01956621,  0.02604181,  0.02092848,  0.01933141,  0.01356868,\n",
       "         0.01772103,  0.01344586,  0.01103534,  0.03741053, -0.17904935]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_num = y_hat.shape[0]\n",
    "dy = (y_hat - t) / batch_num\n",
    "dy    # softmax값의 출력으로 Loss를 미분한 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-consideration",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "polyphonic-terrain",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 라벨을 One-hot 인코딩하는 함수\n",
    "def _change_ont_hot_label(X, num_category):\n",
    "    T = np.zeros((X.size, num_category))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "Y_digit = y_train[:5]\n",
    "t = _change_ont_hot_label(Y_digit, 10)\n",
    "t     # 정답 라벨의 One-hot 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "historical-student",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3881477175652597"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
    "\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-bronze",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acquired-pursuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02176688,  0.02840879,  0.02189248,  0.01976052,  0.01309314,\n",
       "        -0.1839807 ,  0.01276212,  0.01205533,  0.0293117 ,  0.02492973],\n",
       "       [-0.17975727,  0.03017864,  0.02021959,  0.01941245,  0.01126083,\n",
       "         0.01689275,  0.01393851,  0.01154803,  0.03422212,  0.02208435],\n",
       "       [ 0.0237011 ,  0.02948237,  0.02540966,  0.01641073, -0.18978735,\n",
       "         0.01561649,  0.01479889,  0.0109042 ,  0.0320069 ,  0.02145702],\n",
       "       [ 0.01908193, -0.16993201,  0.02120276,  0.01889285,  0.01338442,\n",
       "         0.02220483,  0.01405607,  0.01181776,  0.02741587,  0.02187552],\n",
       "       [ 0.01956621,  0.02604181,  0.02092848,  0.01933141,  0.01356868,\n",
       "         0.01772103,  0.01344586,  0.01103534,  0.03741053, -0.17904935]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_num = y_hat.shape[0]\n",
    "dy = (y_hat - t) / batch_num\n",
    "dy    # softmax값의 출력으로 Loss를 미분한 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-guest",
   "metadata": {},
   "source": [
    "dy가 구해지면 다른 기울기들은 chain-rule로 쉽게 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "robust-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "dW2 = np.dot(z1.T, dy)    \n",
    "db2 = np.sum(dy, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-balance",
   "metadata": {},
   "source": [
    "중간에 sigmoid가 한번 사용되었으므로, 활성화함수에 대한 gradient도 고려한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "shared-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "another-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz1 = np.dot(dy, W2.T)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dW1 = np.dot(X.T, da1)\n",
    "db1 = np.sum(dz1, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-klein",
   "metadata": {},
   "source": [
    "learning_rate도 고려를 하여 파라미터를 업데이트하는 함수를 정의하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "seeing-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-slovak",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "affine_layer_forward(X, W, b)에 대응하여 생각해 보면 해당 레이어의 backpropagation 함수를 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "valid-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_layer_backward(dy, cache):\n",
    "    X, W, b = cache\n",
    "    dX = np.dot(dy, W.T)\n",
    "    dW = np.dot(X.T, dy)\n",
    "    db = np.sum(dy, axis=0)\n",
    "    return dX, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-problem",
   "metadata": {},
   "source": [
    "위 과정을 통해 Forward Propagation과 Backward Propagation이 이루어지는 한 사이클을 아래와 같이 엮어 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "gentle-brave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1629072  0.10205027 0.0871849  0.03690095 0.08553424 0.08402313\n",
      "  0.0927562  0.0880999  0.11439626 0.14614694]\n",
      " [0.14234871 0.10913804 0.09185538 0.03962454 0.08535264 0.07115312\n",
      "  0.07451097 0.10169734 0.15213993 0.13217931]\n",
      " [0.14277873 0.112599   0.08454152 0.04227599 0.11104016 0.08981326\n",
      "  0.08687212 0.10079157 0.10318525 0.1261024 ]\n",
      " [0.16795617 0.10213342 0.08682348 0.04440486 0.08285717 0.08799251\n",
      "  0.08743328 0.099039   0.12290014 0.11845996]\n",
      " [0.12808293 0.09871113 0.09247266 0.03432466 0.10572351 0.07935199\n",
      "  0.08716148 0.09672532 0.11346556 0.16398076]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.1426966709941766\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "# Forward Propagation\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "\n",
    "# 추론과 오차(Loss) 계산\n",
    "y_hat = softmax(a2)\n",
    "t = _change_ont_hot_label(Y_digit, 10)   # 정답 One-hot 인코딩\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "print(y_hat)\n",
    "print(t)\n",
    "print('Loss: ', Loss)\n",
    "        \n",
    "dy = (y_hat - t) / X.shape[0]\n",
    "dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "\n",
    "# 경사하강법을 통한 파라미터 업데이트    \n",
    "learning_rate = 0.1\n",
    "W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-screen",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "minute-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "def train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=False):\n",
    "    a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "    z1 = sigmoid(a1)\n",
    "    a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "    y_hat = softmax(a2)\n",
    "    t = _change_ont_hot_label(Y, 10)\n",
    "    Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "    if verbose:\n",
    "        print('---------')\n",
    "        print(y_hat)\n",
    "        print(t)\n",
    "        print('Loss: ', Loss)\n",
    "        \n",
    "    dy = (y_hat - t) / X.shape[0]\n",
    "    dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "    da1 = sigmoid_grad(a1) * dz1\n",
    "    dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "    \n",
    "    W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "    \n",
    "    return W1, b1, W2, b2, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "directed-medicaid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "[[0.09339471 0.04248273 0.13503946 0.05860919 0.10154272 0.09879126\n",
      "  0.15725866 0.13264596 0.060242   0.11999331]\n",
      " [0.107262   0.04177426 0.1504036  0.05435546 0.10287041 0.09420832\n",
      "  0.16218741 0.11927546 0.05864536 0.10901772]\n",
      " [0.07589836 0.04888933 0.14085082 0.0679027  0.08760608 0.09782427\n",
      "  0.15231145 0.14710828 0.05290995 0.12869877]\n",
      " [0.10513945 0.04426112 0.1335127  0.05699658 0.10501071 0.11064156\n",
      "  0.15242733 0.12766821 0.05383744 0.1105049 ]\n",
      " [0.10161571 0.05052207 0.14674969 0.05740623 0.08914823 0.10745151\n",
      "  0.12455904 0.1491024  0.04683708 0.12660804]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.4332879479315768\n",
      "---------\n",
      "[[0.11408139 0.05386074 0.11090332 0.0544783  0.11628996 0.12132735\n",
      "  0.12674071 0.11028678 0.05626164 0.1357698 ]\n",
      " [0.13899437 0.05418291 0.1202756  0.05001611 0.11896932 0.11299411\n",
      "  0.12790571 0.09655432 0.05449945 0.12560811]\n",
      " [0.09068349 0.06121915 0.11750566 0.06316305 0.10723258 0.11291484\n",
      "  0.12592669 0.12386058 0.04978363 0.14771032]\n",
      " [0.12650762 0.05748698 0.10919399 0.05287922 0.12016238 0.12833348\n",
      "  0.12318766 0.10574486 0.05041565 0.12608817]\n",
      " [0.12250981 0.06405061 0.11830678 0.05278358 0.10286085 0.12405282\n",
      "  0.09888305 0.12226717 0.0434306  0.15085473]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.212594947975531\n",
      "---------\n",
      "[[0.1311258  0.06506062 0.09245586 0.04963071 0.12666953 0.14111932\n",
      "  0.10423441 0.09256313 0.05135482 0.1457858 ]\n",
      " [0.16762798 0.06638012 0.09754222 0.04487373 0.12962817 0.1271408\n",
      "  0.10283591 0.07873207 0.04922793 0.13601107]\n",
      " [0.10234856 0.07331521 0.09936996 0.05767448 0.12512186 0.1238678\n",
      "  0.10599416 0.10525027 0.04587439 0.1611833 ]\n",
      " [0.14360435 0.07127726 0.09087589 0.04822507 0.13109864 0.1413415\n",
      "  0.10181439 0.08867898 0.0463128  0.13677112]\n",
      " [0.13875383 0.07729575 0.09699073 0.04758761 0.11270637 0.13549414\n",
      "  0.08020789 0.1014024  0.03938308 0.1701782 ]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.0469423654661485\n",
      "---------\n",
      "[[0.14452635 0.07596225 0.07829797 0.04489725 0.1336852  0.15848702\n",
      "  0.08735442 0.07868513 0.04646052 0.15164388]\n",
      " [0.19257316 0.07819572 0.08045394 0.03990795 0.13615613 0.13740483\n",
      "  0.08433339 0.06505412 0.04398975 0.14193102]\n",
      " [0.1109764  0.08500251 0.08523534 0.05229598 0.14153925 0.13141956\n",
      "  0.09070436 0.09051292 0.04190764 0.17040605]\n",
      " [0.15664069 0.08551667 0.07699509 0.04376501 0.13885653 0.15063326\n",
      "  0.08590521 0.07550531 0.04227281 0.14390943]\n",
      " [0.1506302  0.09013829 0.0809677  0.04265523 0.11963126 0.14292652\n",
      "  0.06641264 0.08539064 0.03543687 0.18581065]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.9173222169189692\n",
      "---------\n",
      "[[0.1546822  0.08640515 0.06727869 0.04058998 0.13824329 0.17394356\n",
      "  0.07443096 0.06775696 0.0419562  0.15471301]\n",
      " [0.21399038 0.08944635 0.06747124 0.03547026 0.13977333 0.14472348\n",
      "  0.07044167 0.05453947 0.03923652 0.14490731]\n",
      " [0.11694842 0.09607385 0.07407529 0.04736077 0.1568631  0.13636326\n",
      "  0.07875121 0.07877117 0.038192   0.17660094]\n",
      " [0.16618609 0.10001879 0.06629773 0.03974732 0.14432919 0.15716192\n",
      "  0.07378741 0.06523595 0.03857396 0.14866164]\n",
      " [0.15881035 0.10239667 0.06874227 0.03826398 0.12447163 0.14745563\n",
      "  0.05600375 0.07301686 0.03186523 0.19897363]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.8120421340079826\n"
     ]
    }
   ],
   "source": [
    "X = x_train_reshaped[:5]\n",
    "Y = y_train[:5]\n",
    "\n",
    "# train_step을 다섯 번 반복 돌립니다.\n",
    "for i in range(5):\n",
    "    W1, b1, W2, b2, _ = train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-linux",
   "metadata": {},
   "source": [
    "## 추론 과정 구현과 정확도(Accuracy) 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "elegant-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W1, b1, W2, b2, X):\n",
    "    a1 = np.dot(X, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    y = softmax(a2)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "accurate-cylinder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16214698, 0.09619185, 0.05855763, 0.03678507, 0.14103227,\n",
       "       0.18798574, 0.06433169, 0.05904789, 0.03795225, 0.15596862])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = x_train[:100] 에 대해 모델 추론을 시도합니다. \n",
    "\n",
    "X = x_train_reshaped[:100]\n",
    "Y = y_test[:100]\n",
    "result = predict(W1, b1, W2, b2, X)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dress-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(W1, b1, W2, b2, x, y):\n",
    "    y_hat = predict(W1, b1, W2, b2, x)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "   # t = np.argmax(t, axis=1)\n",
    "\n",
    "    accuracy = np.sum(y_hat == y) / float(x.shape[0])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "christian-fishing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16214698 0.09619185 0.05855763 0.03678507 0.14103227 0.18798574\n",
      " 0.06433169 0.05904789 0.03795225 0.15596862]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "0.08\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(W1, b1, W2, b2, X, Y)\n",
    "\n",
    "t = _change_ont_hot_label(Y, 10)\n",
    "print(result[0])\n",
    "print(t[0])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-subcommittee",
   "metadata": {},
   "source": [
    "## 전체 학습 사이클 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "interracial-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습시킬 파라미터를 초기화하는 함수\n",
    "def init_params(input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "\n",
    "    W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "    b1 = np.zeros(hidden_size)\n",
    "    W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "    b2 = np.zeros(output_size)\n",
    "\n",
    "    print(W1.shape)\n",
    "    print(b1.shape)\n",
    "    print(W2.shape)\n",
    "    print(b2.shape)\n",
    "    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "distinguished-value",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(50, 10)\n",
      "(10,)\n",
      "Loss:  2.3009319579526983\n",
      "train acc, test acc | 0.09736666666666667, 0.0982\n",
      "Loss:  0.8077654284030023\n",
      "train acc, test acc | 0.7883333333333333, 0.7899\n",
      "Loss:  0.47335996359950483\n",
      "train acc, test acc | 0.8769833333333333, 0.8796\n",
      "Loss:  0.3167373073186053\n",
      "train acc, test acc | 0.8975666666666666, 0.9021\n",
      "Loss:  0.25351652962297655\n",
      "train acc, test acc | 0.907, 0.9108\n",
      "Loss:  0.25546877562962844\n",
      "train acc, test acc | 0.91445, 0.9159\n",
      "Loss:  0.2819074148213252\n",
      "train acc, test acc | 0.9189166666666667, 0.9203\n",
      "Loss:  0.29942099028680275\n",
      "train acc, test acc | 0.9239333333333334, 0.9255\n",
      "Loss:  0.43182325953006734\n",
      "train acc, test acc | 0.9262, 0.9259\n",
      "Loss:  0.2597094177390444\n",
      "train acc, test acc | 0.9301166666666667, 0.9325\n",
      "Loss:  0.17218113237991736\n",
      "train acc, test acc | 0.9332166666666667, 0.934\n",
      "Loss:  0.3431769194420081\n",
      "train acc, test acc | 0.9366166666666667, 0.9355\n",
      "Loss:  0.16956513399939585\n",
      "train acc, test acc | 0.9388666666666666, 0.9393\n",
      "Loss:  0.15327199012966353\n",
      "train acc, test acc | 0.94185, 0.9406\n",
      "Loss:  0.18164351390992448\n",
      "train acc, test acc | 0.9432333333333334, 0.9425\n",
      "Loss:  0.27178817151674867\n",
      "train acc, test acc | 0.9458833333333333, 0.9439\n",
      "Loss:  0.2213440093747469\n",
      "train acc, test acc | 0.94765, 0.9449\n",
      "Loss:  0.15362143376789683\n",
      "train acc, test acc | 0.9487666666666666, 0.9466\n",
      "Loss:  0.1422255415432678\n",
      "train acc, test acc | 0.9508, 0.9475\n",
      "Loss:  0.1418272936685984\n",
      "train acc, test acc | 0.9524666666666667, 0.9496\n",
      "Loss:  0.1116679631649264\n",
      "train acc, test acc | 0.9535166666666667, 0.9502\n",
      "Loss:  0.05636654339454937\n",
      "train acc, test acc | 0.9542, 0.9516\n",
      "Loss:  0.12907707621623385\n",
      "train acc, test acc | 0.95575, 0.9526\n",
      "Loss:  0.14507758288410247\n",
      "train acc, test acc | 0.9565166666666667, 0.9532\n",
      "Loss:  0.16777418274345057\n",
      "train acc, test acc | 0.9578, 0.9533\n",
      "Loss:  0.21505512334027457\n",
      "train acc, test acc | 0.9588166666666667, 0.9541\n",
      "Loss:  0.2588460414763287\n",
      "train acc, test acc | 0.9593166666666667, 0.9548\n",
      "Loss:  0.059472174782253556\n",
      "train acc, test acc | 0.96035, 0.9559\n",
      "Loss:  0.22795536861571655\n",
      "train acc, test acc | 0.9613, 0.9559\n",
      "Loss:  0.18210149177293922\n",
      "train acc, test acc | 0.9621166666666666, 0.9576\n",
      "Loss:  0.1256384264378138\n",
      "train acc, test acc | 0.96285, 0.959\n",
      "Loss:  0.19448350331407507\n",
      "train acc, test acc | 0.9637, 0.9593\n",
      "Loss:  0.09519557593453389\n",
      "train acc, test acc | 0.9638666666666666, 0.9598\n",
      "Loss:  0.0546340109876207\n",
      "train acc, test acc | 0.96425, 0.959\n",
      "Loss:  0.08477185723259291\n",
      "train acc, test acc | 0.9652833333333334, 0.9606\n",
      "Loss:  0.14617086902330848\n",
      "train acc, test acc | 0.9658833333333333, 0.9601\n",
      "Loss:  0.07650992479873431\n",
      "train acc, test acc | 0.9666833333333333, 0.9611\n",
      "Loss:  0.16710473059259812\n",
      "train acc, test acc | 0.9672833333333334, 0.9609\n",
      "Loss:  0.07967884294299392\n",
      "train acc, test acc | 0.9673666666666667, 0.9611\n",
      "Loss:  0.11568744812039337\n",
      "train acc, test acc | 0.96845, 0.9621\n",
      "Loss:  0.0773823104908842\n",
      "train acc, test acc | 0.96935, 0.962\n",
      "Loss:  0.04469053683512997\n",
      "train acc, test acc | 0.9695666666666667, 0.9621\n",
      "Loss:  0.14528136127280022\n",
      "train acc, test acc | 0.9699833333333333, 0.9623\n",
      "Loss:  0.11942864859822286\n",
      "train acc, test acc | 0.9707666666666667, 0.9628\n",
      "Loss:  0.11018631527234499\n",
      "train acc, test acc | 0.9714333333333334, 0.9633\n",
      "Loss:  0.11111480435186656\n",
      "train acc, test acc | 0.97135, 0.9635\n",
      "Loss:  0.09601110530832775\n",
      "train acc, test acc | 0.9720166666666666, 0.9642\n",
      "Loss:  0.10172944318637869\n",
      "train acc, test acc | 0.9724166666666667, 0.9643\n",
      "Loss:  0.10334840748255605\n",
      "train acc, test acc | 0.9727, 0.9654\n",
      "Loss:  0.05932213957894247\n",
      "train acc, test acc | 0.9733166666666667, 0.9652\n",
      "Loss:  0.1951764624702907\n",
      "train acc, test acc | 0.9738166666666667, 0.9652\n",
      "Loss:  0.04326894150381157\n",
      "train acc, test acc | 0.97415, 0.9651\n",
      "Loss:  0.06405892036366995\n",
      "train acc, test acc | 0.97475, 0.9663\n",
      "Loss:  0.05132440303559735\n",
      "train acc, test acc | 0.9746, 0.9661\n",
      "Loss:  0.15481198379011193\n",
      "train acc, test acc | 0.9751, 0.966\n",
      "Loss:  0.1222524826811018\n",
      "train acc, test acc | 0.9758666666666667, 0.967\n",
      "Loss:  0.09252945889419119\n",
      "train acc, test acc | 0.9761, 0.9662\n",
      "Loss:  0.09002232891771067\n",
      "train acc, test acc | 0.9755833333333334, 0.9672\n",
      "Loss:  0.05277360584406535\n",
      "train acc, test acc | 0.9763833333333334, 0.9668\n",
      "Loss:  0.12737305495723883\n",
      "train acc, test acc | 0.9768, 0.9674\n",
      "Loss:  0.07656922010798667\n",
      "train acc, test acc | 0.9769666666666666, 0.9675\n",
      "Loss:  0.06941185648542589\n",
      "train acc, test acc | 0.97745, 0.9678\n",
      "Loss:  0.035124375524051406\n",
      "train acc, test acc | 0.9775666666666667, 0.9682\n",
      "Loss:  0.09117297155699611\n",
      "train acc, test acc | 0.9780833333333333, 0.9683\n",
      "Loss:  0.05753001639855393\n",
      "train acc, test acc | 0.9781166666666666, 0.9687\n",
      "Loss:  0.030689737473294988\n",
      "train acc, test acc | 0.9786333333333334, 0.9691\n",
      "Loss:  0.051255644549864\n",
      "train acc, test acc | 0.9784833333333334, 0.9681\n",
      "Loss:  0.10674334323458144\n",
      "train acc, test acc | 0.9790333333333333, 0.9686\n",
      "Loss:  0.07015914211619352\n",
      "train acc, test acc | 0.9791833333333333, 0.9687\n",
      "Loss:  0.0386869350725874\n",
      "train acc, test acc | 0.9790833333333333, 0.9685\n",
      "Loss:  0.04120287863352818\n",
      "train acc, test acc | 0.98, 0.9694\n",
      "Loss:  0.0409957914136476\n",
      "train acc, test acc | 0.9804166666666667, 0.9689\n",
      "Loss:  0.12320199445456495\n",
      "train acc, test acc | 0.9801666666666666, 0.9699\n",
      "Loss:  0.04749643757405532\n",
      "train acc, test acc | 0.9805166666666667, 0.9689\n",
      "Loss:  0.06868078531649967\n",
      "train acc, test acc | 0.9805833333333334, 0.9703\n",
      "Loss:  0.04083480031103731\n",
      "train acc, test acc | 0.9807, 0.9704\n",
      "Loss:  0.07719137424985881\n",
      "train acc, test acc | 0.9811833333333333, 0.9705\n",
      "Loss:  0.046746757305481355\n",
      "train acc, test acc | 0.98135, 0.9702\n",
      "Loss:  0.07546942722483603\n",
      "train acc, test acc | 0.9816666666666667, 0.9697\n",
      "Loss:  0.021872740703788796\n",
      "train acc, test acc | 0.98155, 0.9706\n",
      "Loss:  0.08076051883853194\n",
      "train acc, test acc | 0.9821166666666666, 0.9702\n",
      "Loss:  0.0272304203970166\n",
      "train acc, test acc | 0.9819666666666667, 0.9701\n",
      "Loss:  0.051606518318308085\n",
      "train acc, test acc | 0.98215, 0.9702\n",
      "Loss:  0.0374373865881017\n",
      "train acc, test acc | 0.9823333333333333, 0.9702\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "iters_num = 50000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "W1, b1, W2, b2 = init_params(784, 50, 10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train_reshaped[batch_mask]\n",
    "    y_batch = y_train[batch_mask]\n",
    "    \n",
    "    W1, b1, W2, b2, Loss = train_step(x_batch, y_batch, W1, b1, W2, b2, learning_rate=0.1, verbose=False)\n",
    "\n",
    "    # 학습 경과 기록\n",
    "    train_loss_list.append(Loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        print('Loss: ', Loss)\n",
    "        train_acc = accuracy(W1, b1, W2, b2, x_train_reshaped, y_train)\n",
    "        test_acc = accuracy(W1, b1, W2, b2, x_test_reshaped, y_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "extraordinary-ending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 6 \n",
    "\n",
    "# Accuracy 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "religious-venice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss 그래프 그리기\n",
    "x = np.arange(len(train_loss_list))\n",
    "plt.plot(x, train_loss_list, label='train acc')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, 3.0)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-brazilian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
