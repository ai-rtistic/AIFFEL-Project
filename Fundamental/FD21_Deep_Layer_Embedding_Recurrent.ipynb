{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "included-argument",
   "metadata": {},
   "source": [
    "# Fundamental 21. 딥러닝 레이어의 이해 - Embedding, Recurrent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-assembly",
   "metadata": {},
   "source": [
    "## Embedding 레이어\n",
    "### 원-핫 인코딩  One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "presidential-premiere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "vocab = {      # 사용할 단어 사전 정의\n",
    "    \"i\": 0,\n",
    "    \"need\": 1,\n",
    "    \"some\": 2,\n",
    "    \"more\": 3,\n",
    "    \"coffee\": 4,\n",
    "    \"cake\": 5,\n",
    "    \"cat\": 6,\n",
    "    \"dog\": 7\n",
    "}\n",
    "\n",
    "sentence = \"i i i i need some more coffee coffee coffee\"\n",
    "# 위 sentence\n",
    "_input = [vocab[w] for w in sentence.split()]  # [0, 0, 0, 0, 1, 2, 3, 4, 4, 4]\n",
    "\n",
    "vocab_size = len(vocab)   # 8\n",
    "\n",
    "one_hot = tf.one_hot(_input, vocab_size)\n",
    "print(one_hot.numpy())    # 원-핫 인코딩 벡터를 출력해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-handle",
   "metadata": {},
   "source": [
    "생성된 원-핫 벡터를 Linear 레이어에 넣어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "removable-turkey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Weight\n",
      "[[ 0.14386714 -0.28959525]\n",
      " [ 0.01624763 -0.47682944]\n",
      " [-0.32366136 -0.49629986]\n",
      " [ 0.10942185  0.19583851]\n",
      " [ 0.2834351   0.5339401 ]\n",
      " [ 0.18905717 -0.32596153]\n",
      " [-0.03354037 -0.70990115]\n",
      " [-0.487678    0.47108424]]\n",
      "\n",
      "One-Hot Linear Result\n",
      "[[ 0.14386714 -0.28959525]\n",
      " [ 0.14386714 -0.28959525]\n",
      " [ 0.14386714 -0.28959525]\n",
      " [ 0.14386714 -0.28959525]\n",
      " [ 0.01624763 -0.47682944]\n",
      " [-0.32366136 -0.49629986]\n",
      " [ 0.10942185  0.19583851]\n",
      " [ 0.2834351   0.5339401 ]\n",
      " [ 0.2834351   0.5339401 ]\n",
      " [ 0.2834351   0.5339401 ]]\n"
     ]
    }
   ],
   "source": [
    "distribution_size = 2   # 보기 좋게 2차원으로 분산 표현\n",
    "linear = tf.keras.layers.Dense(units=distribution_size, use_bias=False)\n",
    "one_hot_linear = linear(one_hot)\n",
    "\n",
    "print(\"Linear Weight\")\n",
    "print(linear.weights[0].numpy())\n",
    "\n",
    "print(\"\\nOne-Hot Linear Result\")\n",
    "print(one_hot_linear.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-wedding",
   "metadata": {},
   "source": [
    "원-핫 벡터에 Linear 레이어를 적용하니 Linear 레이어의 Weight에서 단어 인덱스 배열 `[ 0, 0, 0, 0, 1, 2, 3, 4, 4, 4 ]` 에 해당하는 행만 읽어오는 효과가 있는 것을 확인 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-strategy",
   "metadata": {},
   "source": [
    "### Embedding 레이어 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "restricted-desperate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding을 진행할 문장: (1, 3)\n",
      "Embedding된 문장: (1, 3, 100)\n",
      "Embedding Layer의 Weight 형태: (64, 100)\n"
     ]
    }
   ],
   "source": [
    "some_words = tf.constant([[3, 57, 35]])\n",
    "# 3번 단어 / 57번 단어 / 35번 단어로 이루어진 한 문장입니다.\n",
    "\n",
    "print(\"Embedding을 진행할 문장:\", some_words.shape)\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=64, output_dim=100)\n",
    "# 총 64개의 단어를 포함한 Embedding 레이어를 선언할 것이고,\n",
    "# 각 단어는 100차원으로 분산표현 할 것입니다.\n",
    "\n",
    "print(\"Embedding된 문장:\", embedding_layer(some_words).shape)\n",
    "print(\"Embedding Layer의 Weight 형태:\", embedding_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-climate",
   "metadata": {},
   "source": [
    " 기본적으로 딥러닝은 미분을 기반으로 동작하는데, Embedding 레이어는 그저 단어를 대응 시켜 줄 뿐이니 미분이 불가능하다.  \n",
    " 따라서 신경망 설계를 할 때 __어떤 연산 결과를 Embedding 레이어에 연결시키는 것은 불가능__ 하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-thread",
   "metadata": {},
   "source": [
    "__Embedding 레이어는 입력에 직접 연결되게 사용__해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-shareware",
   "metadata": {},
   "source": [
    "----\n",
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "precious-journalist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN에 입력할 문장: What time is it ?\n",
      "Embedding을 위해 단어 매핑: [[2 3 0 1 4]]\n",
      "입력 문장 데이터 형태: (1, 5)\n",
      "\n",
      "Embedding 결과: (1, 5, 100)\n",
      "Embedding Layer의 Weight 형태: (5, 100)\n",
      "\n",
      "RNN 결과 (모든 Step Output): (1, 5, 64)\n",
      "RNN Layer의 Weight 형태: (100, 64)\n",
      "\n",
      "RNN 결과 (최종 Step Output): (1, 64)\n",
      "RNN Layer의 Weight 형태: (100, 64)\n"
     ]
    }
   ],
   "source": [
    "sentence = \"What time is it ?\"\n",
    "dic = {\n",
    "    \"is\": 0,\n",
    "    \"it\": 1,\n",
    "    \"What\": 2,\n",
    "    \"time\": 3,\n",
    "    \"?\": 4\n",
    "}\n",
    "\n",
    "print(\"RNN에 입력할 문장:\", sentence)\n",
    "\n",
    "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
    "\n",
    "print(\"Embedding을 위해 단어 매핑:\", sentence_tensor.numpy())\n",
    "print(\"입력 문장 데이터 형태:\", sentence_tensor.shape)\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
    "emb_out = embedding_layer(sentence_tensor)\n",
    "\n",
    "print(\"\\nEmbedding 결과:\", emb_out.shape)\n",
    "print(\"Embedding Layer의 Weight 형태:\", embedding_layer.weights[0].shape)\n",
    "\n",
    "rnn_seq_layer = \\\n",
    "tf.keras.layers.SimpleRNN(units=64, return_sequences=True, use_bias=False)\n",
    "rnn_seq_out = rnn_seq_layer(emb_out)\n",
    "\n",
    "print(\"\\nRNN 결과 (모든 Step Output):\", rnn_seq_out.shape)\n",
    "print(\"RNN Layer의 Weight 형태:\", rnn_seq_layer.weights[0].shape)\n",
    "\n",
    "rnn_fin_layer = tf.keras.layers.SimpleRNN(units=64, use_bias=False)\n",
    "rnn_fin_out = rnn_fin_layer(emb_out)\n",
    "\n",
    "print(\"\\nRNN 결과 (최종 Step Output):\", rnn_fin_out.shape)\n",
    "print(\"RNN Layer의 Weight 형태:\", rnn_fin_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-dynamics",
   "metadata": {},
   "source": [
    "떤 문장이 긍정인지 부정인지 나누기 위해서라면 문장을 모두 읽은 후, 최종 Step의 Output만 확인해도 판단이 가능하다.   \n",
    "\n",
    "\n",
    "하지만 문장을 생성하는 경우라면 이전 단어를 입력으로 받아 생성된 모든 다음 단어, 즉 모든 Step에 대한 Output이 필요하다. 그것은 위 코드에서 `tf.keras.layers.SimpleRNN` 레이어의 `return_sequences` 인자를 조절함으로써 조절할 수 있다.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/84179578/129540191-fb32a84a-821d-4c17-a0f6-de8dd782ec94.png)\n",
    "\n",
    "- (좌) 모든 Step에 대한 Output이 필요한 경우 (return_sequences=True)  \n",
    "- (우) 최종 Step에 대한 Output만 필요한 경우 (return_sequences=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-progressive",
   "metadata": {},
   "source": [
    "## LSTM (Long Short-Term Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-speaker",
   "metadata": {},
   "source": [
    "위 코드에서 RNN 레이어에 대한 부분은 이렇게 바꿀 수도 있다. 동작하는 방식은 위 코드와 동일함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seeing-astronomy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "LSTM 결과 (모든 Step Output): (1, 5, 64)\n",
      "LSTM Layer의 Weight 형태: (100, 256)\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "LSTM 결과 (최종 Step Output): (1, 64)\n",
      "LSTM Layer의 Weight 형태: (100, 256)\n"
     ]
    }
   ],
   "source": [
    "lstm_seq_layer = tf.keras.layers.LSTM(units=64, return_sequences=True, use_bias=False)\n",
    "lstm_seq_out = lstm_seq_layer(emb_out)\n",
    "\n",
    "print(\"\\nLSTM 결과 (모든 Step Output):\", lstm_seq_out.shape)\n",
    "print(\"LSTM Layer의 Weight 형태:\", lstm_seq_layer.weights[0].shape)\n",
    "\n",
    "lstm_fin_layer = tf.keras.layers.LSTM(units=64, use_bias=False)\n",
    "lstm_fin_out = lstm_fin_layer(emb_out)\n",
    "\n",
    "print(\"\\nLSTM 결과 (최종 Step Output):\", lstm_fin_out.shape)\n",
    "print(\"LSTM Layer의 Weight 형태:\", lstm_fin_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-breast",
   "metadata": {},
   "source": [
    "LSTM 레이어를 사용하는 경우, Embedding 벡터의 차원수(unit) 의 크기가 동일 할 때, Weight 의 크기가 위에서 사용했던 SimpleRNN 의 4배나 되는 것을 확인 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-times",
   "metadata": {},
   "source": [
    "## GRU (Gated Recurrent Unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-broadcasting",
   "metadata": {},
   "source": [
    "LSTM의 변형 모델로 소개되는 Gated Recurrent Unit(GRU)도 `tf.keras.layers.GRU()` 로 선언해서 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hybrid-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "GRU 결과 (모든 Step Output): (1, 5, 64)\n",
      "GRU Layer의 Weight 형태: (100, 192)\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "\n",
      "GRU 결과 (최종 Step Output): (1, 64)\n",
      "GRU Layer의 Weight 형태: (100, 192)\n"
     ]
    }
   ],
   "source": [
    "gru_seq_layer = tf.keras.layers.GRU(units=64, return_sequences=True, use_bias=False)\n",
    "gru_seq_out = gru_seq_layer(emb_out)\n",
    "\n",
    "print(\"\\nGRU 결과 (모든 Step Output):\", gru_seq_out.shape)\n",
    "print(\"GRU Layer의 Weight 형태:\", gru_seq_layer.weights[0].shape)\n",
    "\n",
    "gru_fin_layer = tf.keras.layers.GRU(units=64, use_bias=False)\n",
    "gru_fin_out = gru_fin_layer(emb_out)\n",
    "\n",
    "print(\"\\nGRU 결과 (최종 Step Output):\", gru_fin_out.shape)\n",
    "print(\"GRU Layer의 Weight 형태:\", gru_fin_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-circus",
   "metadata": {},
   "source": [
    "LSTM에 비해 GRU가 학습할 가중치(Weight)가 더 적은 것을 확인 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-metropolitan",
   "metadata": {},
   "source": [
    "## 양방향(Bidirectional) RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "elegant-concern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장 데이터 형태: (1, 5, 100)\n",
      "Bidirectional RNN 결과 (모든 Step Output): (1, 5, 128)\n",
      "\n",
      "Bidirectional RNN 결과 (최종 Step Output): (1, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sentence = \"What time is it ?\"\n",
    "dic = {\n",
    "    \"is\": 0,\n",
    "    \"it\": 1,\n",
    "    \"What\": 2,\n",
    "    \"time\": 3,\n",
    "    \"?\": 4\n",
    "}\n",
    "\n",
    "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
    "emb_out = embedding_layer(sentence_tensor)\n",
    "\n",
    "print(\"입력 문장 데이터 형태:\", emb_out.shape)\n",
    "\n",
    "bi_rnn = \\\n",
    "tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.SimpleRNN(units=64, use_bias=False, return_sequences=True)\n",
    ")\n",
    "bi_out = bi_rnn(emb_out)\n",
    "\n",
    "print(\"Bidirectional RNN 결과 (모든 Step Output):\", bi_out.shape)\n",
    "\n",
    "\n",
    "\n",
    "bi_fin = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.SimpleRNN(units=64, use_bias=False,))\n",
    "\n",
    "bi_fin_out = bi_fin(emb_out)\n",
    "\n",
    "print(\"\\nBidirectional RNN 결과 (최종 Step Output):\", bi_fin_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-thailand",
   "metadata": {},
   "source": [
    "Bidirectional RNN은 순방향 Weight와 역방향 Weight를 각각 정의하므로 위에서 다룬 RNN의 2배 크기 Weight가 정의된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-macintosh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
