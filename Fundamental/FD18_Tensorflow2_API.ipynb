{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solid-issue",
   "metadata": {},
   "source": [
    "# Fundamental 17. Tensorflow2 API\n",
    "\n",
    "## Tensorflow2 API로 모델 구성: MNIST 데이터셋\n",
    "\n",
    "###  MNIST 데이터셋 : Sequential API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "entertaining-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "boxed-premises",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-process",
   "metadata": {},
   "source": [
    "Sequential Model 구성  \n",
    "Spec:\n",
    "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "3. Flatten 레이어\n",
    "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reasonable-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comparable-joseph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 17s 7ms/step - loss: 0.2108 - accuracy: 0.9317 0s - loss: 0.2122 - accuracy\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0332 - accuracy: 0.9901\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0189 - accuracy: 0.9941\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0112 - accuracy: 0.9965\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0073 - accuracy: 0.9977\n",
      "313/313 - 2s - loss: 0.0668 - accuracy: 0.9843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06675118952989578, 0.9843000173568726]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-collaboration",
   "metadata": {},
   "source": [
    "### MNIST 데이터셋 : Functional API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "earned-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "valuable-glasgow",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-columbia",
   "metadata": {},
   "source": [
    "`keras.Input`으로 정의된 input및 output 레이어 구성을 통해 model을 구현  \n",
    "\n",
    "\n",
    "Spec:\n",
    "0. (28X28X1) 차원으로 정의된 Input\n",
    "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "3. Flatten 레이어\n",
    "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "assigned-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = keras.layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(128, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "occasional-southwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2321 - accuracy: 0.9283\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0338 - accuracy: 0.9897\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0172 - accuracy: 0.9946\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0111 - accuracy: 0.9963\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0072 - accuracy: 0.9977\n",
      "313/313 - 1s - loss: 0.0513 - accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0512717179954052, 0.987500011920929]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-concentration",
   "metadata": {},
   "source": [
    "### MNIST 데이터셋 : Subclassing 활용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mounted-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "front-monaco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-episode",
   "metadata": {},
   "source": [
    "`keras.Model` 을 상속받은 클래스를 만들자.  \n",
    "`__init__()` 메소드 안에서 레이어를 선언하고, `call()` 메소드 안에서 forward propagation을 구현한다.  \n",
    "\n",
    "_Functional 방식과 비교하자면, `call()`의 입력이 Input이고, `call()`의 리턴값이 Output이 되는 것_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tracked-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.conv2 = keras.layers.Conv2D(64, 3, activation='relu')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(128, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "corrected-monthly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2049 - accuracy: 0.9367\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0332 - accuracy: 0.9894\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0164 - accuracy: 0.9945\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0124 - accuracy: 0.9955\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0090 - accuracy: 0.9967\n",
      "313/313 - 1s - loss: 0.0566 - accuracy: 0.9860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05664738640189171, 0.9860000014305115]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-evolution",
   "metadata": {},
   "source": [
    "----\n",
    "## Tensorflow2 API로 모델 구성: CIFAR-100 데이터셋\n",
    "\n",
    "[CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "###  CIFAR-100 데이터셋 : Sequential API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "royal-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "executive-candle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-civilian",
   "metadata": {},
   "source": [
    "Sequential Model 구성  \n",
    "\n",
    "\n",
    "Spec:\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "minus-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "polyphonic-pearl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 3.9975 - accuracy: 0.0962\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9513 - accuracy: 0.2710\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6272 - accuracy: 0.3402\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3901 - accuracy: 0.3878\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2123 - accuracy: 0.4270\n",
      "313/313 - 1s - loss: 2.6050 - accuracy: 0.3524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.604952812194824, 0.352400004863739]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-resident",
   "metadata": {},
   "source": [
    "### CIFAR-100 데이터셋 : Functional API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "postal-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "suitable-conversion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-hudson",
   "metadata": {},
   "source": [
    "Functional API를 활용한 Model 구성  \n",
    "\n",
    "\n",
    "Spec:\n",
    "0. (32X32X3) 차원으로 정의된 Input\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "metric-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(inputs)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "liked-valentine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.9594 - accuracy: 0.1042\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9193 - accuracy: 0.2802\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6076 - accuracy: 0.3436\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3695 - accuracy: 0.3943\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1796 - accuracy: 0.4365\n",
      "313/313 - 1s - loss: 2.5447 - accuracy: 0.3644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5447332859039307, 0.3643999993801117]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-costs",
   "metadata": {},
   "source": [
    "### CIFAR-100 데이터셋 : Subclassing 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hydraulic-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "systematic-mistake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-pearl",
   "metadata": {},
   "source": [
    "Subclassing을 활용한 Model 구성  \n",
    "\n",
    "\n",
    "Spec:\n",
    "0. keras.Model 을 상속받았으며, __init__()와 call() 메소드를 가진 모델 클래스\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "7. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "genetic-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "competitive-there",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 4.0155 - accuracy: 0.0912\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9975 - accuracy: 0.2645\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6599 - accuracy: 0.3321\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4366 - accuracy: 0.3775\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2669 - accuracy: 0.4146\n",
      "313/313 - 1s - loss: 2.6033 - accuracy: 0.3563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6032817363739014, 0.3562999963760376]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-sailing",
   "metadata": {},
   "source": [
    "----\n",
    "## GradientTape 활용\n",
    "\n",
    "아래에서는 이전 스텝에서 진행했던 학습을 `tf.GradientTape` 를 이용한 것으로 변형했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "historical-worse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 모델 구성부분\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-fleet",
   "metadata": {},
   "source": [
    "- `tape.gradient()`를 통해 매 스텝 학습이 진행될 때마다 발생하는 그래디언트를 추출한 후 \n",
    "- `optimizer.apply_gradients()`를 통해 발생한 그래디언트가 업데이트해야 할 파라미터 `model.trainable_variables` 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "brazilian-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# tf.GradientTape()를 활용한 train_step\n",
    "def train_step(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features)\n",
    "        loss = loss_func(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "interpreted-september",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: last batch loss = 4.5313\n",
      "Epoch 1: last batch loss = 4.4994\n",
      "Epoch 2: last batch loss = 4.5539\n",
      "Epoch 3: last batch loss = 4.5735\n",
      "Epoch 4: last batch loss = 4.3571\n",
      "It took 93.1763801574707 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def train_model(batch_size=32):   # model.fit() 메소드와 기능적으로 동일\n",
    "    start = time.time()\n",
    "    for epoch in range(5):\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for step, (x, y) in enumerate(zip(x_train, y_train)):\n",
    "            if step % batch_size == batch_size-1:\n",
    "                x_batch.append(x)\n",
    "                y_batch.append(y)\n",
    "                loss = train_step(np.array(x_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32))\n",
    "                x_batch = []\n",
    "                y_batch = []\n",
    "        print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
    "    print(\"It took {} seconds\".format(time.time() - start))\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-testimony",
   "metadata": {},
   "source": [
    "`tf.GradientTape()`를 활용하면 `model.compile()`과 `model.fit()` 안에 감추어져 있던 한 스텝의 학습 단계(위 예제에서는 train_step 메소드)를 끄집어내서 자유롭게 재구성할 수 있게 된다.  \n",
    "\n",
    "그동안 흔히 다루어 왔던 지도학습 방식과 다른 강화학습 또는 GAN(Generative Advasarial Network)의 학습을 위해서는 train_step 메소드의 재구성이 필수적이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "preliminary-partner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0633"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "prediction = model.predict(x_test, batch_size=x_test.shape[0], verbose=1)\n",
    "temp = sum(np.squeeze(y_test) == np.argmax(prediction, axis=1))\n",
    "temp/len(y_test)  # Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-czech",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
